---
layout:     post                    
title:      Challenge: Factors that may have impacts on the fertility desire in China            # 标题 
subtitle:   Microeconometrics #副标题
date:       2019-04-13              # 时间
author:     ELVIS                      # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - Microeconometrics
---
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>

# Challenge: Factors that may influence the fertility desire in China     

I downloaded the CGSS data version 2015 to take a detailed look into contributors for Chinese birth preference, make some primary selection on potential independent variables based on our common knowledge, then I formed a dta file. Now let me illustrate the logic why I choose those feature variables as our regressors.    

There are a number of available independent factors to be chosen, taking into the feature into account, I divide the possible choices into several dimensions, such as religion, household income, education, and political orientation, the list is going on. Since I have got known about the basic direction, I just spilit this big picture into dozens of detail ones and finally, I construct a matrix that contains exactly fifty explaining variables, as well as one explained variable, the fertility desire which illustrates how many kids one wants to give birth to without One-Child policy limitation.     

In my dataset the target variable is denoted as *a371*, and all the other facrors, discrete or not, are feature variables. I'll put an appendix to tell the meaning of those fifty contributors. Now Let's first look at the OLS regression result:   

![OLS]( https://i.loli.net/2019/04/21/5cbc3981c9fe4.jpg )    

From the chart above we can conclude that dozens of explaining variables are insignificant, now we can explore what will happen if we switch to the logistic method:   

![Logistic]( https://i.loli.net/2019/04/21/5cbc3bbb3a466.jpg )    

Well, the logit results are also unsatisfying. As we can see, many variables's performance does not match my expectation, maybe a better filter mechanism is needed. Lasso method just comes to my mind and I think it will make a difference.     
![LASSO](https://i.loli.net/2019/04/21/5cbc3e9e9f18d.jpg)
![plotpath(lambda)](https://i.loli.net/2019/04/21/5cbc3dbcce91f.png)     

As we can see, the Lasso method does present an inner look of those feature variables. It is clear that the fitness result will change with value of lambda, now I need to find out the best lambda which can give us the best result.    

![the best lambda](https://i.loli.net/2019/04/21/5cbc40a1087a8.jpg)      

The value with star in the first chart is the outcome we are seeking for. And the following chart shows the result under the condition that lambda is equal to 85.66. We can see that there are 30 variables shown on the table, which means that twenty feature variables have zero coefficients. LASSO helps me find out the relatively important contributors. Coefficients on the right column presents the outcome before LASSO, since LASSO method sometimes lead to a bias as a result of 



